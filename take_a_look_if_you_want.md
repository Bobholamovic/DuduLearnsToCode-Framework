# 一些杂乱的想法

## 一半是framework，一半是template

这里说的framework是指利用hook一类的技术让代码复用程度尽量高，调用者只需要利用少许暴露出来的API就可以轻松实现强大的功能。相比这些frameworks，这个项目需要开发者做更多的编程工作，比如写一些类的继承、自己写一些辅助的函数之类的，甚至训练过程也需要自己定制。但这其实也带来了一个优势，那就是更高的自由度。

按照我的理解，template是指一些模板文件，把重复性的代码基本都写好，然后剩下的一些代码由开发者根据需要改写和扩充。这无疑给了开发者极大的自由，但如果要更新模板的话则比较费事。在这个项目里，`src/core`文件夹里的东西是全部的核心组件，更新`src/core`不会影响其它部分，从这点上看`src/core`像是一个独立的library（实际上也被实现为一个git submodule的形式，有自己独立的版本控制），这样更新核心功能的时候只需要更新这个文件夹的内容，相对来说也不会太麻烦。

本质上，这个项目还是提供一个可以改写和套用的模板，所以名字是Template而不是Framework。

## 关于`Duck`

`Duck`类在`src/core/factories.py`中，可以说是这个项目一种比较核心的数据结构。其实`Duck`类的出发点很简单，就是对于有些深度学习任务来说，可能需要不止一个模型（例如GAN）、不止一个数据集或者诸如此类，而这些模型、数据集的一部分行为是一致的。比如，现在有两个模型，我想让它们都进入训练模式，那么比起：

```python
model1.train()
model2.train()
```

或者

```python
for model in models:
  model.train()
```

我还是更希望能直接这样写：

```python
model.train()
```

然后就能实现上面两段代码的功能，看上去就好像我只有一个模型一样。如果我能有这样一个`model`的话，除了写法上简洁，还有一个好处就是我之前为单个模型写的代码在一定程度上可以复用了，我不用为了考虑多个模型的情况硬是把所有出现`model`的地方都替换成`for model in models`。当然，这只是针对读取、存储模型状态、或者`model.train()`之类操作而言的，真正使用两个模型，比如使用GAN的生成器和对抗器进行训练的时候，我还是需要把两个models拆开来用。所以，为了让之前的那些旧代码不用做大修改，同时又能适应多个模型、多个数据集之类的新情况，我搞了个`DuckModel`类，名字取自duck typing。这个类本身是一个容器，封装1个以上的`nn.Module`，我对它的要求是，它的部分对外接口需要与被封装的`nn.Module`类一致，同时又支持把容器里面的东西取出来用。`DuckDataLoader`、`DuckOptimizer`、`DuckCriterion`之类的也是基于类似的思想设计的，其中，`DuckOptimizer`中的每个优化器对象都需要绑定`DuckModel`中的一个模型，这是从实际出发考虑的。

## 关于builders

builders就是建造器，在`src/core/factories.py`中被使用。每个builder都必须是一个可调用对象。在创建模型、优化器等对象的时候，工厂函数会根据一定的规则从Registry中取出合适的建造器。

例如，对于模型工厂来说，首先会在Registry中尝试匹配`MODEL_MODELS_DATASETS_model`，这里的`MODEL`表示当前需要构造的模型名，`MODELS`表示指定的全部模型（如`'UNet+UNet'`），而`DATASET`则表示指定的全部数据集；接着会匹配`MODEL_DATASETS_model`；最后匹配`MODEL_model`。如果匹配成功，工厂就会调用builder构造出对象。如果三次匹配都失败，那么就返回错误。为什么按照这样的顺序进行匹配呢？主要是出于如下考虑：假设模型`M1`，对于数据集`D1`和`D2`需要不同的参数，而当`M1`和另一个模型`M2`一起使用的时候，又需要另外不同的参数。在这种情况下，如果用单一的builder来构造`M1`，可能会让这个builder过于复杂，因此我们可以通过组合不同的`MODELS`和`DATASETS`的条件，从一个“限定条件比较多的builder”逐步查找匹配到一个“限定条件比较少的builder”。

## 关于`OutPathGetter`

`OutPathGetter`这个类在`src/core/misc.py`中，我喜欢用Global Path Controller（gpc）代指一个`OutPathGetter`对象，因为它往往用在全局路径控制。gpc维护一个目录树，这个目录树代表着“在这次程序运行过程中gpc所能看到的目录结构”，而gpc的主要用途也就是管理这个目录树上的路径。开发者可以往gpc中添加新的路径让目录树得到更新，也可以通过gpc构造想要的路径。比如，首先给一个目录`blabla/out/duduisaduck/`打上“标签”，在gpc那里登记一下，我打算叫这个目录`out`。接下来，在项目的其它部分，只需要调用gpc的`get_path`方法就可以往这个被标记过的`out`文件夹里写东西，而不需要把那个路径作为参数传递或者打成硬编码。除此之外，通过在合适的时刻打印目录树，我们还可以即时知道，程序用到了哪些路径，以及这些路径之间的相对关系、目录结构是什么样的。

## 简单的配置系统

这个项目目前的配置系统比较简单，主要原因是我个人对现在比较流行的“各部分完全可配置、程序依赖于配置文件”的方式有些不习惯。除了配置文件和命令行选项以外，项目还提供了builders作为一种配置参数的手段，用于分担一部分配置文件的职能，降低整体configurable的程度。相比`yaml`文件，builders的一个优势是可以编写代码逻辑。关于配置风格更进一步的讨论在[下一节](#code-more-or-config-more)会提到。

配置文件的naming convention是：

```
config_TAG{_SUFFIX}.yaml
```

`{}`里的部分可以省略。如果运行程序时指定了config文件，程序运行后，会在实验目录下创建或找到一个名为`TAG`的文件夹，然后把实验得到的结果都放在里面。而`SUFFIX`则象征着一种更细粒度的划分：同一个`TAG`、不同的`SUFFIX`会导致`TAG`文件夹中存在不同组的实验结果，这些实验结果之间用不同的`SUFFIX`作为后缀区分。比如：`model_best_arch1.pth`、`model_best_arch2.pth`。

目前只支持对同一目录下的配置文件有限的单继承（从配置文件名解析）。

使用命令行选项设置参数也是支持的。如果命令行选项和配置文件同时给一个配置项指定了值，那么优先级顺序为：`命令行选项指定值 > 配置文件 > 命令行选项默认值`。命令行选项分为静态和动态两种：静态的命令行选项由`src/core/config.py`中的部分和`train.py`中`parser_configurator`钩子函数里追加的部分组成；而动态的命令行选项是解析配置文件后动态生成的，因此在指定不同的配置文件时可用的命令行选项可能也有所不同。根据开发者的喜好和实际需求，可以使用静态或动态命令行选项。只使用静态命令行选项的好处是，使用配置文件能做到的，使用命令行选项也完全可以实现，缺点是可能会导致一个很长的、不干净的命令行选项列表，一般适用于“以命令行选项为主要配置手段、不使用配置文件或以配置文件为辅助手段”的项目。使用配置文件+动态命令行选项的好处是，不需要把所有的配置项都事先在`ArgumentParser`中定义好，模块化程度更高，缺点是如果不指定配置文件就无法设置某些命令行选项，一般适用于“以配置文件为主要配置手段、偶尔用或者基本不用命令行选项”的项目。

## code more or config more

现有的机制给开发者提供了自由选择的机会：对于一个可调节的参数，可以选择通过写builder这种硬编码的手法来处理，也可以从配置文件中导入，还可以直接在命令行选项里指定。在同一个项目里可以混用这三种方式。

举个例子，比如现在要新增一个可以选用的模型`M`，它在数据集`D1`上需要一套参数，在数据集`D2`上需要另一套参数。这里的“参数”可以是模型的输入通道数，也可以是学习率、batch size等等。我认为这些参数其实并不都是一类东西，应该分开讨论：类似通道数这样的参数，我认为是属于“模型和数据集确定了之后就基本不变”的内容，因此比较适合硬编码在builder里，而不需要每次都跟着config文件走；而学习率、batch size这类超参数，可能是需要不断尝试和调整的，因此属于经常变动的内容，比较适合写在配置文件里。实际上，还有第三类参数，比如数据集在电脑上的位置，这种应该是属于设定过一次就几乎不可能再变化的东西，所以我把它们放在`src/constants.py`里。

上面只是举个例子，配置的风格全看个人喜好。作为一个开发者来说，可以选择多写点代码（写builders），也可以选择多花些时间鼓捣配置文件（写配置文件）。根据项目的大小、用途，可以采用不同的风格。

## 关于程序主入口

实际上，训练（train）和评估（evaluate）模型都以`src/train.py`作为入口，这使得`train.py`这个名字多少有些误导。这是因为如果将evaluation过程定义为“数据集有标签、能汇报精度”的一个过程，那么其实模型训练过程中的验证（validation）阶段也是在做evaluation，因此可以直接复用validation部分的代码。另外一个入口`test.py`我将其规划为用于“数据集没有标签、不能汇报精度”情况的测试脚本。

## 关于`Trainer`

`Trainer`是负责训练和验证过程的主体。Trainer的`__init__`中实现了对model、optimizer等各种所需对象的构造，`run`作为训练和验证的总入口，而`train_epoch`和`eval_epoch`则由继承者重写。`Trainer`的逻辑较为复杂（需要进一步解耦），有两部分值得注意：

- `_resume_from_checkpoint`这个方法具有如下功能：训练阶段，加载完全匹配或部分匹配的checkpoint并汇报载入的参数个数；验证阶段，需要checkpoint中包含模型所有的参数，否则返回`False`。

- 学习率调整的部分。因为某些问题，项目的核心组件中目前并没有集成`torch.optim.lr_scheduler`系列的学习率调度器。继承`Trainer`后，开发者可以通过重写`init_learning_rate`和`adjust_learning_rate`定制自己的学习率调整策略。

对`Trainer`的继承是自由的和受到鼓励的，开发者可以根据自己的需求，利用面向对象编程的诸多优势，定制一个或多个自己的trainer。

`TrainerSwitcher`是一个有用的类，功能就和它的名字一样。Registry中存有一个全局的`TrainerSwitcher`对象，当项目中存在多个trainer时，可以根据一定的条件、按照指定的优先级顺序进行筛选，以找到合适的trainer。

## 关于`DatasetBase`

数据集的抽象基类，其中值得注意的是`subset`和`phase`的区别。前者指的是“验证模型时所用的子集”，后者指的是“所处阶段”。例如，`phase=='eval', subset=='train'`，就可以实现在训练集上验证模型效果。`subset`和`phase`的可能取值中均需要包含`train`表示训练集或训练阶段。

## 关于数据增广和数据预处理

`utils.data_utils`中的`augmentations.py`和`preprocessors.py`分别提供了数据增广和预处理的一些辅助类。关于数据增广和数据预处理的区别，我定义为前者“可能包含一个随机状态”（比如随机裁块、随机缩放），而后者是一个确定性的过程（比如中心裁剪）。这些都只是辅助工具，并不强制开发者必须使用。不过值得一提的是，相比很多有名的图像处理库，`augmentations.py`和`preprocessors.py`中的处理类具有一个特色，就是支持对任意多个`numpy`数组同时进行变换，这对要求多幅输入图像的问题应该比较有用。

## 调试模式

开发过程中总要调试，建议在命令行选项中指定`--debug_on`以启用事后调试。对于开发者来说，可以在恰当的地方根据`Trainer`的`self.debug_on`属性来定制调试期间应该具备的行为。

## 应用

一个完整的使用此模板的项目在[这里](https://github.com/Bobholamovic/CDLab)，加入了`tensorboard`和`lr_scheduler`支持。